{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8312d718-25db-4f35-bc30-7399581e25ae",
   "metadata": {},
   "source": [
    "# Task 3: Customer Churn Prediction (Bank Customers) \n",
    "## Objective: \n",
    "#### Identify customers who are likely to leave the bank. \n",
    "## Dataset: \n",
    " ### Churn Modelling Dataset \n",
    "## Instructions: \n",
    "#### ● Clean and prepare the dataset. \n",
    "#### ● Encode categorical features such as geography and gender. \n",
    "#### ● Train a classification model. \n",
    "#### ● Analyze feature importance to understand what influences churn. \n",
    "## Skills: \n",
    "#### ● Categorical data encoding (Label Encoding / One-Hot Encoding) \n",
    "#### ● Supervised classification modeling \n",
    "#### ● Understanding and interpreting feature importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2de9d-bbc1-4461-8bcb-57bba3087437",
   "metadata": {},
   "source": [
    "# Here's The Python Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab38170-a1d0-4206-9922-634e88ddfde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3/Churn_Modelling DataSet.csv — shape: (10000, 14)\n",
      "\n",
      "Model ROC-AUC scores:\n",
      " - LogisticRegression: ROC-AUC = 0.7919\n",
      " - RandomForest: ROC-AUC = 0.8531\n",
      " - HistGradientBoosting: ROC-AUC = 0.8578\n",
      ">>> Best model selected: HistGradientBoosting\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\01_churn_count.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\02_geo_vs_churn.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\03_gender_exited.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\04_age_hist.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\05_age_balance_scatter.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\06_credit_score_hist.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\07_tenure_counts.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\08_num_products.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\09_balance_boxplot.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\10_estimated_salary_hist.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\11_balance_salary_hexbin.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\12_correlation_heatmap.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\13_credit_violin.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\14_age_boxplot.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\15_active_member_stacked.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\16_hascrcard_exited.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\17_churn_rate_by_tenure.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\18_roc_best_model.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\19_feature_importance.png\n",
      "Saved: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\20_permutation_importances.png\n",
      "\n",
      "Saved predictions sample to: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\\predictions_sample.csv\n",
      "SHAP not installed or failed — skipping SHAP plots. (Optional: pip install shap)\n",
      "\n",
      "All done. 20 visualizations + predictions saved in: C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3\\output\n",
      "Best model: HistGradientBoosting\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Task 3:\n",
    "   — Customer Churn Prediction (Bank Customers) \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------- Path -------------------------------\n",
    "\n",
    "default_windows_path = r\"C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 3/Churn_Modelling DataSet.csv\"\n",
    "\n",
    "\n",
    "# Fallback (when running in a different environment)\n",
    "fallback_path = \"/mnt/data/Churn_Modelling DataSet.csv\"\n",
    "\n",
    "csv_path = default_windows_path if os.path.exists(default_windows_path) else fallback_path\n",
    "if not os.path.exists(csv_path):\n",
    "    print(\"CSV not found at default paths. Please edit csv_path variable to point to your CSV file.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# Directory to save outputs (same directory as CSV)\n",
    "base_dir = os.path.dirname(csv_path)\n",
    "output_dir = os.path.join(base_dir, \"output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# ---------- Load dataset ----------\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Loaded dataset from {csv_path} — shape: {df.shape}\")\n",
    "\n",
    "\n",
    "# ---------- Quick cleaning ----------\n",
    "# Remove ID-like columns that aren't helpful to ML\n",
    "drop_cols = [c for c in [\"RowNumber\", \"CustomerId\", \"Surname\"] if c in df.columns]\n",
    "df_clean = df.drop(columns=drop_cols).copy()\n",
    "\n",
    "\n",
    "# Fill missing values if any (median imputation for numerics)\n",
    "if df_clean.isnull().any().any():\n",
    "    print(\"Missing values detected — applying median imputation for numerical columns.\")\n",
    "    num_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    df_clean[num_cols] = df_clean[num_cols].fillna(df_clean[num_cols].median())\n",
    "\n",
    "# Create a few derived features (useful for interpretation)\n",
    "df_clean[\"BalanceZero\"] = (df_clean[\"Balance\"] == 0).astype(int)\n",
    "df_clean[\"HighBalance\"] = (df_clean[\"Balance\"] > df_clean[\"Balance\"].median()).astype(int)\n",
    "df_clean[\"Senior\"] = (df_clean[\"Age\"] >= 60).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Split features & target ----------\n",
    "TARGET = \"Exited\"\n",
    "if TARGET not in df_clean.columns:\n",
    "    raise ValueError(f\"Expected target column '{TARGET}' in dataset.\")\n",
    "\n",
    "X = df_clean.drop(columns=[TARGET])\n",
    "y = df_clean[TARGET]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- LabelEncoder wrapper for ColumnTransformer ----------\n",
    "class LabelEncoderWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "    def fit(self, X, y=None):\n",
    "        arr = np.asarray(X).ravel()\n",
    "        self.le.fit(arr)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        arr = np.asarray(X).ravel()\n",
    "        return self.le.transform(arr).reshape(-1, 1)\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "\n",
    "# ---------- Column transformer ----------\n",
    "cat_cols = [c for c in [\"Geography\", \"Gender\"] if c in X.columns]\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"onehot_geo\", OneHotEncoder(drop=\"first\", sparse_output=False), [\"Geography\"]) if \"Geography\" in X.columns else (\"noop\", \"passthrough\", []),\n",
    "    (\"label_gender\", LabelEncoderWrapper(), [\"Gender\"]) if \"Gender\" in X.columns else (\"noop2\", \"passthrough\", [])\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Train-test split ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.2)\n",
    "preprocessor.fit(X_train)  # fit on training data\n",
    "\n",
    "# Helper to derive post-transform feature names\n",
    "def get_feature_names_from_preprocessor(preprocessor, X):\n",
    "    feature_names = []\n",
    "    # preprocessor.transformers_ available after fit\n",
    "    for name, trans, cols in preprocessor.transformers_:\n",
    "        if name == \"remainder\":\n",
    "            if trans == \"passthrough\":\n",
    "                remainder_cols = [c for c in X.columns if c not in sum([list(t[2]) for t in preprocessor.transformers_ if t[0]!=\"remainder\"], [])]\n",
    "                feature_names.extend(remainder_cols)\n",
    "            else:\n",
    "                feature_names.extend(cols)\n",
    "        else:\n",
    "            if hasattr(trans, \"get_feature_names_out\"):\n",
    "                try:\n",
    "                    out = trans.get_feature_names_out(cols)\n",
    "                    feature_names.extend(out.tolist())\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        out = trans.get_feature_names(cols)\n",
    "                        feature_names.extend(out)\n",
    "                    except Exception:\n",
    "                        feature_names.extend(cols)\n",
    "            else:\n",
    "                feature_names.extend(cols)\n",
    "    return feature_names\n",
    "\n",
    "feature_names = get_feature_names_from_preprocessor(preprocessor, X_train)\n",
    "\n",
    "\n",
    "# ---------- Scale data ----------\n",
    "scaler = StandardScaler()\n",
    "X_train_trans = preprocessor.transform(X_train)\n",
    "scaler.fit(X_train_trans)\n",
    "X_test_trans = preprocessor.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test_trans)\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Models ----------\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1200, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "pipelines = {}\n",
    "for name, model in models.items():\n",
    "    # build a simple pipeline wrapper so we can call predict_proba on raw X\n",
    "    pipelines[name] = Pipeline([(\"pre\", preprocessor), (\"scale\", scaler), (\"model\", model)])\n",
    "    pipelines[name].fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ---------- Evaluate models ----------\n",
    "results = {}\n",
    "for name, pipe in pipelines.items():\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    try:\n",
    "        y_proba = pipe.predict_proba(X_test)[:,1]\n",
    "    except Exception:\n",
    "        # fallback\n",
    "        y_proba = pipe.predict(X_test)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    results[name] = {\"roc_auc\": roc, \"report\": classification_report(y_test, y_pred, output_dict=True)}\n",
    "\n",
    "best_model_name = max(results, key=lambda k: results[k][\"roc_auc\"])\n",
    "best_pipeline = pipelines[best_model_name]\n",
    "best_model = best_pipeline.named_steps[\"model\"]\n",
    "print(\"\\nModel ROC-AUC scores:\")\n",
    "for name, res in results.items():\n",
    "    print(f\" - {name}: ROC-AUC = {res['roc_auc']:.4f}\")\n",
    "print(f\">>> Best model selected: {best_model_name}\")\n",
    "\n",
    "# ---------- Permutation importance on the scaled test matrix ----------\n",
    "perm = permutation_importance(best_model, X_test_scaled, y_test, n_repeats=15, random_state=42, n_jobs=-1)\n",
    "perm_idx = perm.importances_mean.argsort()[::-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Visualization settings ----------\n",
    "plt.style.use(\"dark_background\")  # black background\n",
    "# friendly dark palette (cycled)\n",
    "palette = [\n",
    "    \"#01b3a7\", \"#ff7b00\", \"#ffd60a\", \"#9b5de5\", \"#f15bb5\",\n",
    "    \"#00bbf9\", \"#00f5d4\", \"#ff6b6b\", \"#8ac926\", \"#1982c4\"\n",
    "]\n",
    "\n",
    "def savefig(fig, filename):\n",
    "    path = os.path.join(output_dir, filename)\n",
    "    fig.savefig(path, dpi=220, bbox_inches=\"tight\", facecolor=fig.get_facecolor())\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {path}\")\n",
    "\n",
    "\n",
    "# --------------------- 20 distinct visualizations  ---------------------\n",
    "\n",
    "# 1) Churn count bar\n",
    "fig = plt.figure(figsize=(6,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "counts = df_clean[\"Exited\"].value_counts().sort_index()\n",
    "ax.bar([\"Stayed\",\"Exited\"], counts.values, color=[palette[0], palette[1]])\n",
    "ax.set_title(\"Customer Churn Count\", color=\"white\")\n",
    "savefig(fig, \"01_churn_count.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 2) Geography vs Exited grouped bar\n",
    "if \"Geography\" in df_clean.columns:\n",
    "    fig = plt.figure(figsize=(8,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "    geo_ct = df_clean.groupby([\"Geography\", \"Exited\"]).size().unstack(fill_value=0)\n",
    "    x = np.arange(len(geo_ct.index)); w = 0.35\n",
    "    ax.bar(x - w/2, geo_ct[0].values, w, label=\"Stayed\", color=palette[2])\n",
    "    ax.bar(x + w/2, geo_ct[1].values, w, label=\"Exited\", color=palette[3])\n",
    "    ax.set_xticks(x); ax.set_xticklabels(geo_ct.index, color=\"white\")\n",
    "    ax.set_title(\"Geography vs Churn\", color=\"white\"); ax.legend(facecolor=\"black\", edgecolor=\"white\", labelcolor=\"white\")\n",
    "    savefig(fig, \"02_geo_vs_churn.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 3) Gender vs Exited bar\n",
    "if \"Gender\" in df_clean.columns:\n",
    "    fig = plt.figure(figsize=(6,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "    g_ct = df_clean.groupby([\"Gender\", \"Exited\"]).size().unstack(fill_value=0)\n",
    "    ax.bar(g_ct.index.astype(str), g_ct[1].values, color=palette[4])\n",
    "    ax.set_title(\"Exits by Gender\", color=\"white\"); savefig(fig, \"03_gender_exited.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 4) Age distribution histogram\n",
    "fig = plt.figure(figsize=(8,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "ax.hist(df_clean[\"Age\"], bins=20, color=palette[5], edgecolor=\"white\")\n",
    "ax.set_title(\"Age Distribution\", color=\"white\"); savefig(fig, \"04_age_hist.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 5) Age vs Balance scatter (colored by Exited)\n",
    "fig = plt.figure(figsize=(8,6), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "color_map = df_clean[\"Exited\"].map({0: palette[6], 1: palette[7]})\n",
    "ax.scatter(df_clean[\"Age\"], df_clean[\"Balance\"], s=12, c=color_map, alpha=0.9)\n",
    "ax.set_xlabel(\"Age\", color=\"white\"); ax.set_ylabel(\"Balance\", color=\"white\"); ax.set_title(\"Age vs Balance (by Exited)\", color=\"white\")\n",
    "savefig(fig, \"05_age_balance_scatter.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 6) CreditScore histogram\n",
    "fig = plt.figure(figsize=(8,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "ax.hist(df_clean[\"CreditScore\"], bins=25, color=palette[8], edgecolor=\"white\")\n",
    "ax.set_title(\"Credit Score Distribution\", color=\"white\"); savefig(fig, \"06_credit_score_hist.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 7) Tenure counts (bar)\n",
    "fig = plt.figure(figsize=(10,4), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "ten_ct = df_clean[\"Tenure\"].value_counts().sort_index()\n",
    "ax.bar(ten_ct.index, ten_ct.values, color=palette[0])\n",
    "ax.set_title(\"Customer Count by Tenure\", color=\"white\"); savefig(fig, \"07_tenure_counts.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 8) NumOfProducts distribution (bar)\n",
    "fig = plt.figure(figsize=(6,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "nop_ct = df_clean[\"NumOfProducts\"].value_counts().sort_index()\n",
    "ax.bar(nop_ct.index.astype(str), nop_ct.values, color=palette[1])\n",
    "ax.set_title(\"Number of Products Distribution\", color=\"white\"); savefig(fig, \"08_num_products.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 9) Balance boxplot by Exited\n",
    "fig = plt.figure(figsize=(8,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "b0 = df_clean[df_clean[\"Exited\"]==0][\"Balance\"]; b1 = df_clean[df_clean[\"Exited\"]==1][\"Balance\"]\n",
    "ax.boxplot([b0, b1], labels=[\"Stayed\",\"Exited\"], patch_artist=True, boxprops=dict(facecolor=palette[2], color='white'))\n",
    "ax.set_title(\"Balance by Churn (boxplot)\", color=\"white\"); savefig(fig, \"09_balance_boxplot.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 10) EstimatedSalary histogram\n",
    "fig = plt.figure(figsize=(8,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "ax.hist(df_clean[\"EstimatedSalary\"], bins=25, color=palette[3], edgecolor=\"white\")\n",
    "ax.set_title(\"Estimated Salary Distribution\", color=\"white\"); savefig(fig, \"10_estimated_salary_hist.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 11) Balance vs EstimatedSalary hexbin (dense scatter)\n",
    "fig = plt.figure(figsize=(8,6), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "hb = ax.hexbin(df_clean[\"Balance\"], df_clean[\"EstimatedSalary\"], gridsize=35, cmap=plt.cm.get_cmap(\"plasma\"))\n",
    "ax.set_xlabel(\"Balance\", color=\"white\"); ax.set_ylabel(\"Estimated Salary\", color=\"white\"); ax.set_title(\"Balance vs Estimated Salary (hexbin)\", color=\"white\")\n",
    "cb = fig.colorbar(hb, ax=ax); cb.ax.yaxis.set_tick_params(color=\"white\"); plt.setp(plt.getp(cb.ax.axes, 'yticklabels'), color='white')\n",
    "savefig(fig, \"11_balance_salary_hexbin.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 12) Correlation matrix (imshow heatmap)\n",
    "fig = plt.figure(figsize=(8,6), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "corr = df_clean.select_dtypes(include=[np.number]).corr()\n",
    "cax = ax.imshow(corr, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(len(corr.columns))); ax.set_yticks(range(len(corr.columns)))\n",
    "ax.set_xticklabels(corr.columns, rotation=45, ha=\"right\", color=\"white\"); ax.set_yticklabels(corr.columns, color=\"white\")\n",
    "ax.set_title(\"Correlation Matrix\", color=\"white\"); cb = fig.colorbar(cax, ax=ax); cb.ax.yaxis.set_tick_params(color=\"white\"); plt.setp(plt.getp(cb.ax.axes, 'yticklabels'), color='white')\n",
    "savefig(fig, \"12_correlation_heatmap.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 13) CreditScore by Exited (violin)\n",
    "fig = plt.figure(figsize=(8,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "cs0 = df_clean[df_clean[\"Exited\"]==0][\"CreditScore\"]; cs1 = df_clean[df_clean[\"Exited\"]==1][\"CreditScore\"]\n",
    "parts = ax.violinplot([cs0, cs1], showmeans=True)\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor(palette[4]); pc.set_edgecolor('white')\n",
    "ax.set_xticks([1,2]); ax.set_xticklabels([\"Stayed\",\"Exited\"], color=\"white\"); ax.set_title(\"Credit Score by Churn (violin)\", color=\"white\")\n",
    "savefig(fig, \"13_credit_violin.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 14) Age by Exited boxplot\n",
    "fig = plt.figure(figsize=(8,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "a0 = df_clean[df_clean[\"Exited\"]==0][\"Age\"]; a1 = df_clean[df_clean[\"Exited\"]==1][\"Age\"]\n",
    "ax.boxplot([a0, a1], labels=[\"Stayed\",\"Exited\"], patch_artist=True, boxprops=dict(facecolor=palette[5]))\n",
    "ax.set_title(\"Age by Churn (boxplot)\", color=\"white\"); savefig(fig, \"14_age_boxplot.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 15) IsActiveMember vs Churn (stacked)\n",
    "fig = plt.figure(figsize=(6,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "iam_ct = df_clean.groupby([\"IsActiveMember\", \"Exited\"]).size().unstack(fill_value=0)\n",
    "x = np.arange(len(iam_ct.index))\n",
    "ax.bar(x, iam_ct[0].values, label=\"Stayed\", color=palette[6]); ax.bar(x, iam_ct[1].values, bottom=iam_ct[0].values, label=\"Exited\", color=palette[7])\n",
    "ax.set_xticks(x); ax.set_xticklabels(iam_ct.index.astype(str), color=\"white\"); ax.set_title(\"IsActiveMember vs Churn (stacked)\", color=\"white\"); ax.legend(facecolor=\"black\", edgecolor=\"white\", labelcolor=\"white\")\n",
    "savefig(fig, \"15_active_member_stacked.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 16) HasCrCard vs Exited (simple bar)\n",
    "fig = plt.figure(figsize=(6,5), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "hcc_ct = df_clean.groupby([\"HasCrCard\", \"Exited\"]).size().unstack(fill_value=0)\n",
    "ax.bar(hcc_ct.index.astype(str), hcc_ct[1].values, color=palette[8])\n",
    "ax.set_title(\"Exited by Has Credit Card\", color=\"white\"); savefig(fig, \"16_hascrcard_exited.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 17) Churn rate by Tenure (line)\n",
    "fig = plt.figure(figsize=(10,4), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "tenure_rate = df_clean.groupby(\"Tenure\")[\"Exited\"].mean()\n",
    "ax.plot(tenure_rate.index, tenure_rate.values, marker=\"o\", color=palette[0])\n",
    "ax.set_title(\"Churn Rate by Tenure\", color=\"white\"); ax.set_xlabel(\"Tenure (years)\", color=\"white\")\n",
    "savefig(fig, \"17_churn_rate_by_tenure.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 18) ROC curve for best model\n",
    "fig = plt.figure(figsize=(7,6), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "try:\n",
    "    y_score = best_pipeline.predict_proba(X_test)[:,1]\n",
    "except Exception:\n",
    "    y_score = best_pipeline.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, color=palette[1], label=f\"{best_model_name} (AUC = {roc_auc:.3f})\")\n",
    "ax.plot([0,1],[0,1], linestyle=\"--\", color=\"white\", alpha=0.5)\n",
    "ax.set_title(\"ROC Curve - Best Model\", color=\"white\"); ax.set_xlabel(\"False Positive Rate\", color=\"white\"); ax.set_ylabel(\"True Positive Rate\", color=\"white\")\n",
    "ax.legend(facecolor=\"black\", edgecolor=\"white\", labelcolor=\"white\")\n",
    "savefig(fig, \"18_roc_best_model.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 19) Top feature importances (model or permutation)\n",
    "fig = plt.figure(figsize=(8,6), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "if hasattr(best_model, \"feature_importances_\"):\n",
    "    importances = best_model.feature_importances_\n",
    "    names = feature_names\n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "    top_n = min(15, len(names))\n",
    "    ax.barh(np.array(names)[sorted_idx][:top_n][::-1], importances[sorted_idx][:top_n][::-1], color=palette[2])\n",
    "    ax.set_title(\"Top Feature Importances (model)\", color=\"white\")\n",
    "else:\n",
    "    ax.barh(np.array(feature_names)[perm_idx][:15][::-1], perm.importances_mean[perm_idx][:15][::-1], color=palette[3])\n",
    "    ax.set_title(\"Top Feature Importances (permutation)\", color=\"white\")\n",
    "ax.tick_params(axis='x', colors='white'); ax.tick_params(axis='y', colors='white')\n",
    "savefig(fig, \"19_feature_importance.png\")\n",
    "\n",
    "\n",
    "\n",
    "# 20) Permutation importance full (horizontal)\n",
    "fig = plt.figure(figsize=(10,8), facecolor=\"black\"); ax = fig.add_subplot(111, facecolor=\"black\")\n",
    "imp_means = perm.importances_mean\n",
    "sorted_idx_full = np.argsort(imp_means)[::-1]\n",
    "ax.barh(np.array(feature_names)[sorted_idx_full][:20][::-1], imp_means[sorted_idx_full][:20][::-1], color=palette[4])\n",
    "ax.set_title(\"Permutation Importances (test set)\", color=\"white\"); ax.tick_params(axis='x', colors='white'); ax.tick_params(axis='y', colors='white')\n",
    "savefig(fig, \"20_permutation_importances.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- Save a CSV with predictions for reference ----------------\n",
    "pred_df = X_test.copy()\n",
    "pred_df[\"y_true\"] = y_test.values\n",
    "pred_df[\"y_pred\"] = best_pipeline.predict(X_test)\n",
    "try:\n",
    "    pred_df[\"y_proba\"] = best_pipeline.predict_proba(X_test)[:,1]\n",
    "except Exception:\n",
    "    pred_df[\"y_proba\"] = np.nan\n",
    "predictions_csv = os.path.join(output_dir, \"predictions_sample.csv\")\n",
    "pred_df.to_csv(predictions_csv, index=False)\n",
    "print(f\"\\nSaved predictions sample to: {predictions_csv}\")\n",
    "\n",
    "# ---------- Optional: SHAP explanation (if you have shap installed) ----------\n",
    "try:\n",
    "    import shap\n",
    "    print(\"SHAP available — creating SHAP summary (may take a moment)...\")\n",
    "    # Use a sample for speed\n",
    "    sample = X_test_scaled[:500]\n",
    "    explainer = shap.Explainer(best_model, sample)\n",
    "    shap_values = explainer(sample)\n",
    "    # Save SHAP summary (bar)\n",
    "    shap_fig = plt.figure(figsize=(8,6), facecolor=\"black\")\n",
    "    shap.summary_plot(shap_values, features=sample, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "    shap_out = os.path.join(output_dir, \"shap_summary.png\")\n",
    "    shap_fig.savefig(shap_out, dpi=220, bbox_inches=\"tight\", facecolor=shap_fig.get_facecolor())\n",
    "    plt.close(shap_fig)\n",
    "    print(f\"Saved SHAP summary to: {shap_out}\")\n",
    "except Exception:\n",
    "    print(\"SHAP not installed or failed — skipping SHAP plots. (Optional: pip install shap)\")\n",
    "\n",
    "print(\"\\nAll done. 20 visualizations + predictions saved in:\", output_dir)\n",
    "print(\"Best model:\", best_model_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d98393b-e88c-40b3-8e95-d4a69689372c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
